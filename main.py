from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from database.db import init_db, engine, get_db, Base
from models.database import SaunaDB  # æ˜ç¤ºçš„ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import logging
from routers import sauna_ranking
from force_create_tables import force_create_tables
from sqlalchemy import inspect
from sqlalchemy.sql import text
import time
from sqlalchemy.orm import Session
from services.scraper import SaunaScraper
import crud

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ğŸ”‡ SQLAlchemyã®SQLãƒ­ã‚°ã‚’æŠ‘åˆ¶ï¼ˆã“ã“ã‚’è¿½åŠ ï¼ï¼‰
logging.getLogger("sqlalchemy.engine").setLevel(logging.WARNING)

# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
sauna_scraper = SaunaScraper()

app = FastAPI()

# CORSã®è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–
@app.on_event("startup")
async def startup_event():
    try:
        logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹• - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯")
        inspector = inspect(engine)
        if 'saunas' not in inspector.get_table_names():
            logger.info("saunasãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„ãŸã‚ä½œæˆã—ã¾ã™")
            force_create_tables()
        else:
            logger.info("saunasãƒ†ãƒ¼ãƒ–ãƒ«ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    except Exception as e:
        logger.error(f"èµ·å‹•æ™‚ã®åˆæœŸåŒ–ã§ã‚¨ãƒ©ãƒ¼: {e}")

# ã‚µã‚¦ãƒŠãƒ©ãƒ³ã‚­ãƒ³ã‚°é–¢é€£ã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ç™»éŒ²
app.include_router(sauna_ranking.router)

# ç¢ºèªç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/init-db")
async def manual_init_db():
    """æ‰‹å‹•ã§DBã‚’åˆæœŸåŒ–ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆé–‹ç™ºç”¨ï¼‰"""
    try:
        Base.metadata.create_all(bind=engine)
        return {"message": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸ"}
    except Exception as e:
        logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return {"error": str(e)}

# æ–°ã—ã„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/force-create-tables")
async def manual_force_create_tables():
    """å¼·åˆ¶çš„ã«ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        force_create_tables()
        return {"message": "ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å¼·åˆ¶çš„ã«ä½œæˆã—ã¾ã—ãŸ"}
    except Exception as e:
        logger.error(f"å¼·åˆ¶ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return {"error": str(e)}

@app.get("/debug-db")
async def debug_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿”ã™"""
    try:
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        result = {}
        
        # ã‚¨ãƒ³ã‚¸ãƒ³æƒ…å ±
        result["engine_url"] = str(engine.url).replace(":********@", ":****@")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§
        inspector = inspect(engine)
        result["tables"] = inspector.get_table_names()
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
            result["connection_test"] = "æˆåŠŸ"
            
            # ã‚¹ã‚­ãƒ¼ãƒç¢ºèª
            schema_query = "SELECT schema_name FROM information_schema.schemata"
            schemas = [row[0] for row in conn.execute(text(schema_query))]
            result["schemas"] = schemas
            
            # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨æ¨©é™
            user_query = "SELECT current_user, current_database()"
            user_info = conn.execute(text(user_query)).fetchone()
            result["current_user"] = user_info[0]
            result["current_database"] = user_info[1]
            
        return result
    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }

@app.get("/health")
async def health_check():
    """
    ã‚µãƒ¼ãƒ“ã‚¹ã®å¥åº·çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚‚ç¢ºèªã™ã‚‹
    """
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒã‚§ãƒƒã‚¯
        with engine.connect() as conn:
            # ç°¡å˜ãªã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
            result = conn.execute(text("SELECT 1")).scalar()
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
            inspector = inspect(engine)
            tables = inspector.get_table_names()
            
            return {
                "status": "healthy",
                "database": "connected",
                "tables": tables,
                "timestamp": time.time()
            }
            
    except Exception as e:
        logger.error(f"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Service unhealthy: {str(e)}"
        )

# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ 
@app.get("/api/github-action-scraping")
async def run_github_action_scraping(db: Session = Depends(get_db)):
    """
    GitHub Actionsã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’å«ã‚€
    """
    max_retries = 3
    retry_delay = 5  # seconds
    
    for attempt in range(max_retries):
        try:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
            inspector = inspect(engine)
            if 'saunas' not in inspector.get_table_names():
                logger.info("saunasãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„ãŸã‚ä½œæˆã—ã¾ã™")
                force_create_tables()
            
            # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œ
            scraped_saunas = sauna_scraper.run_scheduled_scraping()
            
            # DBã«ä¿å­˜
            saved_saunas = crud.bulk_upsert_saunas(db, scraped_saunas)
            
            return {
                "message": "Scraping and DB update completed successfully",
                "count": len(saved_saunas)
            }
            
        except Exception as e:
            logger.error(f"è©¦è¡Œ {attempt + 1}/{max_retries} å¤±æ•—: {e}")
            if attempt < max_retries - 1:
                logger.info(f"{retry_delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                time.sleep(retry_delay)
                continue
            raise HTTPException(
                status_code=500,
                detail=f"All retry attempts failed: {str(e)}"
            ) 